
# ğŸš¨ Fraud Detection System

A complete end-to-end ML pipeline to detect fraudulent transactions using engineered features, balanced training, and a deployed interface for predictions.

---

## ğŸ“Œ Problem Statement

Financial fraud is a critical issue. The goal is to **identify fraudulent transactions** using transaction-level data and deploy a system that predicts fraud in real-time.

---

## ğŸ§  Solution Approach (Summary)

1. **Data Preprocessing**
2. **Exploratory Data Analysis (EDA)**
3. **Feature Engineering** (âš ï¸ Avoided label leakage)
4. **SMOTE for Class Balancing**
5. **Model Training (LightGBM & others)**
6. **Model Evaluation with Metrics & Curves**
7. **Model Deployment using Streamlit**
8. **Feature Importance Visualizations**

---

## ğŸ“Š Dataset Summary

| Class       | Count | Percentage |
|-------------|-------|------------|
| Non-Fraud   | 10000 | 89.75%     |
| Fraud       | 1142  | 10.25%     |

âš ï¸ **Highly imbalanced**, requiring SMOTE for better learning.

---

## ğŸ§ª Feature Engineering

Dropped raw balance columns and created smart features to prevent leakage:

```python
balance_diff_orig   = oldbalanceOrg - newbalanceOrig
balance_diff_dest   = newbalanceDest - oldbalanceDest
error_balance_orig  = oldbalanceOrg - amount - newbalanceOrig
error_balance_dest  = oldbalanceDest + amount - newbalanceDest
```

âœ… This logic is modularized in `utils.py` â†’ `transform_features()`.

---

## âš–ï¸ Handling Class Imbalance

Used **SMOTE** (only on training data) to synthetically generate samples of the minority class (`isFraud = 1`).

âœ… Prevents the model from overfitting on majority class.

---

## ğŸ” Model Training

- Models tried: Logistic Regression, Random Forest, LightGBM âœ… (Best)
- Pipeline: `StandardScaler + LightGBM` using `Pipeline`
- Final model saved as: `fraud_detection_pipeline.pkl`

---

## âœ… Model Evaluation

### ğŸ“‹ Classification Report

| Metric     | Non-Fraud | Fraud |
|------------|-----------|-------|
| Precision  | 0.98      | 0.92  |
| Recall     | 0.99      | 0.82  |
| F1-Score   | 0.99      | 0.87  |
| Accuracy   | 0.97 (overall) |

### ğŸ“Œ Confusion Matrix

![Confusion Matrix](images/confusion_matrix.png)

### ğŸ“ˆ ROC Curve

![ROC Curve](images/roc_curve.png)

### ğŸ“‰ Precision-Recall Curve

![PR Curve](images/pr_curve.png)

---

## ğŸ“¦ Model Explainability

Feature importances (LightGBM):

![Feature Importance](images/feature_importance.png)

---

## ğŸŒ Streamlit App

- ğŸ“ File: `app.py`
- Loads pipeline using `joblib`
- Accepts user input: amount, balances, etc.
- Recomputes features â†’ Predicts fraud

ğŸ¯ Live prediction, based on trained pipeline.

---

## ğŸ›  Folder Structure

```
.
â”œâ”€â”€ Fraud_Analysis_Dataset.csv
â”œâ”€â”€ app.py                      â† Streamlit app
â”œâ”€â”€ train_model.ipynb           â† Model training pipeline
â”œâ”€â”€ deploy_model.ipynb          â† Feature testing / sandbox
â”œâ”€â”€ fraud_detection_pipeline.pklâ† Trained model
â”œâ”€â”€ utils.py                    â† Feature engineering logic
â”œâ”€â”€ README.md                   â† You're here!
â”œâ”€â”€ images/                     â† Images for plots
```

---

## ğŸ’¡ Key Takeaways

- Avoided **label leakage** by engineering clean, logical features.
- Used **SMOTE** smartly to balance training.
- Achieved **~0.97 accuracy** with excellent recall using **LightGBM**.
- Built a **streamlit app** for real-time fraud prediction.
- Pipeline is **modular, explainable, and production-ready**.
